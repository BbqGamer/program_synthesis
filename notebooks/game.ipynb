{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0]), {})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import assembly_game\n",
    "\n",
    "game = gym.make(\"Min2Game\")\n",
    "\n",
    "game.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first move the value from %rdi to the return value (%rax), as you can see we immediately get reward of 10 because in one training example result is in the correct spot \\\n",
    "we are getting however the penalty of 1 for every timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RDI: 0>)),\n",
       " (1, (<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RSI: 1>)),\n",
       " (2, (<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RDX: 2>)),\n",
       " (3, (<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RCX: 3>)),\n",
       " (4, (<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RAX: 4>)),\n",
       " (5, (<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RDI: 0>)),\n",
       " (6, (<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RSI: 1>)),\n",
       " (7, (<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RDX: 2>)),\n",
       " (8, (<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RCX: 3>)),\n",
       " (9, (<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RAX: 4>)),\n",
       " (10, (<Instruction.MOV: 0>, <Operand.RDX: 2>, <Operand.RDI: 0>)),\n",
       " (11, (<Instruction.MOV: 0>, <Operand.RDX: 2>, <Operand.RSI: 1>)),\n",
       " (12, (<Instruction.MOV: 0>, <Operand.RDX: 2>, <Operand.RDX: 2>)),\n",
       " (13, (<Instruction.MOV: 0>, <Operand.RDX: 2>, <Operand.RCX: 3>)),\n",
       " (14, (<Instruction.MOV: 0>, <Operand.RDX: 2>, <Operand.RAX: 4>)),\n",
       " (15, (<Instruction.MOV: 0>, <Operand.RCX: 3>, <Operand.RDI: 0>)),\n",
       " (16, (<Instruction.MOV: 0>, <Operand.RCX: 3>, <Operand.RSI: 1>)),\n",
       " (17, (<Instruction.MOV: 0>, <Operand.RCX: 3>, <Operand.RDX: 2>)),\n",
       " (18, (<Instruction.MOV: 0>, <Operand.RCX: 3>, <Operand.RCX: 3>)),\n",
       " (19, (<Instruction.MOV: 0>, <Operand.RCX: 3>, <Operand.RAX: 4>)),\n",
       " (20, (<Instruction.MOV: 0>, <Operand.RAX: 4>, <Operand.RDI: 0>)),\n",
       " (21, (<Instruction.MOV: 0>, <Operand.RAX: 4>, <Operand.RSI: 1>)),\n",
       " (22, (<Instruction.MOV: 0>, <Operand.RAX: 4>, <Operand.RDX: 2>)),\n",
       " (23, (<Instruction.MOV: 0>, <Operand.RAX: 4>, <Operand.RCX: 3>)),\n",
       " (24, (<Instruction.MOV: 0>, <Operand.RAX: 4>, <Operand.RAX: 4>)),\n",
       " (25, (<Instruction.CMP: 1>, <Operand.RDI: 0>, <Operand.RDI: 0>)),\n",
       " (26, (<Instruction.CMP: 1>, <Operand.RDI: 0>, <Operand.RSI: 1>)),\n",
       " (27, (<Instruction.CMP: 1>, <Operand.RDI: 0>, <Operand.RDX: 2>)),\n",
       " (28, (<Instruction.CMP: 1>, <Operand.RDI: 0>, <Operand.RCX: 3>)),\n",
       " (29, (<Instruction.CMP: 1>, <Operand.RDI: 0>, <Operand.RAX: 4>)),\n",
       " (30, (<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RDI: 0>)),\n",
       " (31, (<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RSI: 1>)),\n",
       " (32, (<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RDX: 2>)),\n",
       " (33, (<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RCX: 3>)),\n",
       " (34, (<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RAX: 4>)),\n",
       " (35, (<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RDI: 0>)),\n",
       " (36, (<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RSI: 1>)),\n",
       " (37, (<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RDX: 2>)),\n",
       " (38, (<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RCX: 3>)),\n",
       " (39, (<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RAX: 4>)),\n",
       " (40, (<Instruction.CMP: 1>, <Operand.RCX: 3>, <Operand.RDI: 0>)),\n",
       " (41, (<Instruction.CMP: 1>, <Operand.RCX: 3>, <Operand.RSI: 1>)),\n",
       " (42, (<Instruction.CMP: 1>, <Operand.RCX: 3>, <Operand.RDX: 2>)),\n",
       " (43, (<Instruction.CMP: 1>, <Operand.RCX: 3>, <Operand.RCX: 3>)),\n",
       " (44, (<Instruction.CMP: 1>, <Operand.RCX: 3>, <Operand.RAX: 4>)),\n",
       " (45, (<Instruction.CMP: 1>, <Operand.RAX: 4>, <Operand.RDI: 0>)),\n",
       " (46, (<Instruction.CMP: 1>, <Operand.RAX: 4>, <Operand.RSI: 1>)),\n",
       " (47, (<Instruction.CMP: 1>, <Operand.RAX: 4>, <Operand.RDX: 2>)),\n",
       " (48, (<Instruction.CMP: 1>, <Operand.RAX: 4>, <Operand.RCX: 3>)),\n",
       " (49, (<Instruction.CMP: 1>, <Operand.RAX: 4>, <Operand.RAX: 4>)),\n",
       " (50, (<Instruction.CMOVG: 2>, <Operand.RDI: 0>, <Operand.RDI: 0>)),\n",
       " (51, (<Instruction.CMOVG: 2>, <Operand.RDI: 0>, <Operand.RSI: 1>)),\n",
       " (52, (<Instruction.CMOVG: 2>, <Operand.RDI: 0>, <Operand.RDX: 2>)),\n",
       " (53, (<Instruction.CMOVG: 2>, <Operand.RDI: 0>, <Operand.RCX: 3>)),\n",
       " (54, (<Instruction.CMOVG: 2>, <Operand.RDI: 0>, <Operand.RAX: 4>)),\n",
       " (55, (<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RDI: 0>)),\n",
       " (56, (<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RSI: 1>)),\n",
       " (57, (<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RDX: 2>)),\n",
       " (58, (<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RCX: 3>)),\n",
       " (59, (<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RAX: 4>)),\n",
       " (60, (<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RDI: 0>)),\n",
       " (61, (<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RSI: 1>)),\n",
       " (62, (<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RDX: 2>)),\n",
       " (63, (<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RCX: 3>)),\n",
       " (64, (<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RAX: 4>)),\n",
       " (65, (<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RDI: 0>)),\n",
       " (66, (<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RSI: 1>)),\n",
       " (67, (<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RDX: 2>)),\n",
       " (68, (<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RCX: 3>)),\n",
       " (69, (<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RAX: 4>)),\n",
       " (70, (<Instruction.CMOVG: 2>, <Operand.RAX: 4>, <Operand.RDI: 0>)),\n",
       " (71, (<Instruction.CMOVG: 2>, <Operand.RAX: 4>, <Operand.RSI: 1>)),\n",
       " (72, (<Instruction.CMOVG: 2>, <Operand.RAX: 4>, <Operand.RDX: 2>)),\n",
       " (73, (<Instruction.CMOVG: 2>, <Operand.RAX: 4>, <Operand.RCX: 3>)),\n",
       " (74, (<Instruction.CMOVG: 2>, <Operand.RAX: 4>, <Operand.RAX: 4>)),\n",
       " (75, (<Instruction.RET: 3>,))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from assembly_game.processor import PROCESSOR_ACTIONS\n",
    "\n",
    "list(enumerate(PROCESSOR_ACTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0, 0, 0]),\n",
       " 1,\n",
       " False,\n",
       " False,\n",
       " {'example_0': 'rdi=1 rsi=2 rax=1 rdx=0 rcx=0 cmp_res=0',\n",
       "  'example_1': 'rdi=2 rsi=1 rax=2 rdx=0 rcx=0 cmp_res=0'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.step(4) # MOV %rdi, %rax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the value with the value in %rsi, if $rax happens to be greater then it must be the case that the value %rsi is minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  1,  0,  0, -1,  2,  1,  2,  0,  0,  1]),\n",
       " 0,\n",
       " False,\n",
       " False,\n",
       " {'example_0': 'rdi=1 rsi=2 rax=1 rdx=0 rcx=0 cmp_res=-1',\n",
       "  'example_1': 'rdi=2 rsi=1 rax=2 rdx=0 rcx=0 cmp_res=1'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.step(34) # CMP $rsi, %rax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conditional move all testing examples are \"solved\", as we are getting reward of 20 and penalty of 3 instructions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  1,  0,  0, -1,  2,  1,  1,  0,  0,  1]),\n",
       " 11,\n",
       " False,\n",
       " False,\n",
       " {'example_0': 'rdi=1 rsi=2 rax=1 rdx=0 rcx=0 cmp_res=-1',\n",
       "  'example_1': 'rdi=2 rsi=1 rax=1 rdx=0 rcx=0 cmp_res=1'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.step(59) # CMOVG %rsi, %rax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need to run the RET instructions to observe value of terminated=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  1,  0,  0, -1,  2,  1,  1,  0,  0,  1]),\n",
       " 10,\n",
       " True,\n",
       " False,\n",
       " {'example_0': 'rdi=1 rsi=2 rax=1 rdx=0 rcx=0 cmp_res=-1',\n",
       "  'example_1': 'rdi=2 rsi=1 rax=1 rdx=0 rcx=0 cmp_res=1'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.step(75) # RET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's see how to add timelimit to the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 4 steps the truncated is being set to True, indicating that the episode has ended due to the time limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEPS = 20\n",
    "env = gym.make(\"Min2Game\", max_episode_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstanty/STUDIA/masters_1_sem/program_synthesis/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.4     |\n",
      "|    ep_rew_mean     | 0.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 658      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013471656 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | -0.568      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.8        |\n",
      "|    ep_rew_mean          | 0.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010300072 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.00748     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 8.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.7        |\n",
      "|    ep_rew_mean          | 0.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015624158 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0374     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0527     |\n",
      "|    value_loss           | 0.0643      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 0.73        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016982423 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.4        |\n",
      "|    ep_rew_mean          | 1.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014252876 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0252     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 7.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.6        |\n",
      "|    ep_rew_mean          | 2.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010659636 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.000159    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 2.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 491         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009378219 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | -0.00792    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.4         |\n",
      "|    ep_rew_mean          | 1.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 492          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048424397 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.15        |\n",
      "|    explained_variance   | 0.0231       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 50.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.1         |\n",
      "|    ep_rew_mean          | 0.88         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113629345 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | -0.0064      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.73         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0264      |\n",
      "|    value_loss           | 9.38         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.4        |\n",
      "|    ep_rew_mean          | 1.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016610645 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.34        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0507     |\n",
      "|    value_loss           | 0.787       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.1        |\n",
      "|    ep_rew_mean          | 2.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 491         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015705094 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 3.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.6        |\n",
      "|    ep_rew_mean          | 3.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011808433 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.4         |\n",
      "|    ep_rew_mean          | 5.91         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073409844 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.02        |\n",
      "|    explained_variance   | -0.00225     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    value_loss           | 59.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.7         |\n",
      "|    ep_rew_mean          | 4.21         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 492          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067329137 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4           |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.17         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20          |\n",
      "|    ep_rew_mean          | 5.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009302409 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.0574      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.9         |\n",
      "|    ep_rew_mean          | 12.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062650894 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    value_loss           | 96.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.7         |\n",
      "|    ep_rew_mean          | 9.96         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067078657 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.86        |\n",
      "|    explained_variance   | 0.054        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 206          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.8        |\n",
      "|    ep_rew_mean          | 16.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007164074 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.78       |\n",
      "|    explained_variance   | 0.0896      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.9         |\n",
      "|    ep_rew_mean          | 17.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074298354 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.67        |\n",
      "|    explained_variance   | 0.0911       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 98.8         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 319          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.7         |\n",
      "|    ep_rew_mean          | 27           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 497          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075905267 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.59        |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 173          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 311          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.8        |\n",
      "|    ep_rew_mean          | 34.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004870592 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 512         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20          |\n",
      "|    ep_rew_mean          | 39          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009378914 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 389         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 731         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20           |\n",
      "|    ep_rew_mean          | 52.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 499          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073084803 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.08        |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 395          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 816          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20          |\n",
      "|    ep_rew_mean          | 53.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006907774 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 411         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    value_loss           | 1.07e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7423e39f1100>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RCX: 3>) {'example_0': 'rdi=1 rsi=2 rax=0 rdx=0 rcx=1 cmp_res=0', 'example_1': 'rdi=2 rsi=1 rax=0 rdx=0 rcx=2 cmp_res=0'} 0\n",
      "(<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=0 rcx=1 cmp_res=0', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=0 rcx=2 cmp_res=0'} 1\n",
      "(<Instruction.MOV: 0>, <Operand.RCX: 3>, <Operand.RDX: 2>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=0', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=0'} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RSI: 1>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=0', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=0'} 0\n",
      "(<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RDI: 0>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=1'} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 11\n",
      "(<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 10\n",
      "(<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RDX: 2>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 10\n",
      "(<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=0'} 10\n",
      "(<Instruction.CMP: 1>, <Operand.RAX: 4>, <Operand.RDX: 2>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=0', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 10\n",
      "(<Instruction.MOV: 0>, <Operand.RDX: 2>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=0', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=1'} -1\n",
      "(<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RDI: 0>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=1'} 0\n",
      "(<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RSI: 1>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=1', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=-1'} 0\n",
      "(<Instruction.CMP: 1>, <Operand.RSI: 1>, <Operand.RCX: 3>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=1'} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 11\n",
      "(<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 10\n",
      "(<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=1'} 10\n",
      "(<Instruction.CMOVG: 2>, <Operand.RSI: 1>, <Operand.RCX: 3>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=1'} 10\n",
      "(<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RDX: 2>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=1'} 10\n",
      "(<Instruction.MOV: 0>, <Operand.RDI: 0>, <Operand.RDX: 2>) {'example_0': 'rdi=1 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=-1', 'example_1': 'rdi=2 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=1'} 10\n",
      "False\n",
      "True\n",
      "Episode finished after 20 timestamps\n",
      "total reward 112\n"
     ]
    }
   ],
   "source": [
    "state, _ = env.reset()\n",
    "cumreward = 0\n",
    "for i in range(MAX_STEPS):\n",
    "  action,_ = model.predict(state)\n",
    "  state, reward, terminated, truncated, info = env.step(action)\n",
    "  cumreward +=reward\n",
    "  print(PROCESSOR_ACTIONS[action], info, reward)\n",
    "  if terminated or truncated:\n",
    "    print(terminated)\n",
    "    print(truncated)\n",
    "    print(f\"Episode finished after {i+1} timestamps\")\n",
    "    break\n",
    "print(f\"total reward {cumreward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
