{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "import assembly_game\n",
    "from assembly_game.processor import PROCESSOR_ACTIONS, actions_to_asm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEPS = 30\n",
    "env = gym.make(\"MinGame\", max_episode_steps=MAX_STEPS, size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "\n",
    "class BestTrajectoryCallback(BaseCallback):\n",
    "    def __init__(self, save_path, verbose=0):\n",
    "        super(BestTrajectoryCallback, self).__init__(verbose)\n",
    "        self.save_path = save_path\n",
    "        self.best_reward = -np.inf\n",
    "        self.current_ep_actions = []\n",
    "        self.current_ep_rewards = []\n",
    "        self.results = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Save obs and action at every step\n",
    "        self.current_ep_actions.append(self.locals['actions'])\n",
    "\n",
    "        # Info contains \"episode\" key at the end of an episode\n",
    "        infos = self.locals['infos']\n",
    "        rewards = self.locals['rewards']\n",
    "        self.current_ep_rewards.append(rewards)\n",
    "\n",
    "        for info in infos:\n",
    "            if 'episode' in info:\n",
    "                ep_reward = sum(self.current_ep_rewards)\n",
    "                if ep_reward > self.best_reward:\n",
    "                    self.best_reward = ep_reward\n",
    "                    self._save_trajectory()\n",
    "\n",
    "                self.current_ep_rewards = []\n",
    "                self.current_ep_actions = []\n",
    "                break\n",
    "\n",
    "        return True\n",
    "        \n",
    "    def _save_trajectory(self):\n",
    "        print(f\"New best trajectory found with reward: {self.best_reward}\")\n",
    "        self.results.append((self.num_timesteps, [action[0] for action in self.current_ep_actions], self.best_reward))\n",
    "    \n",
    "    def _on_training_end(self):\n",
    "        # Save the best trajectory to a file\n",
    "        with open(self.save_path, \"w\") as f:\n",
    "            for (timestep, actions, reward) in self.results:\n",
    "                f.write(f\"Timestep: {timestep}, Len: {len(actions)}, Reward: {reward}\\n\")\n",
    "                f.write(actions_to_asm(actions))\n",
    "                f.write(\"\\n\\n\")\n",
    "    \n",
    "callback = BestTrajectoryCallback(verbose=1, save_path=\"results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "New best trajectory found with reward: [0.]\n",
      "New best trajectory found with reward: [30.]\n",
      "New best trajectory found with reward: [60.]\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 20.6     |\n",
      "|    success_rate    | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2627     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 21.2        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1947        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012130821 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | -0.0235     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "New best trajectory found with reward: [75.]\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 24.9        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1792        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009546543 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.3        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 24.4        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010397932 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.29       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 26.4       |\n",
      "|    success_rate         | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1646       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01069422 |\n",
      "|    clip_fraction        | 0.0737     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.27      |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 44         |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 75.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 28.7        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1626        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012113409 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 29.5        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1605        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010106452 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 29.3       |\n",
      "|    success_rate         | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1607       |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00966482 |\n",
      "|    clip_fraction        | 0.0798     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.22      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 49.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 30.2        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1612        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010769849 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 29.4        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1616        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011957923 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 28.6        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011447178 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 30.1        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012680117 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 29.3         |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1619         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126151405 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 28.2        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012525372 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 31.6        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1619        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011086833 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.25        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 33.5        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013015348 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 32.5        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1618        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011813092 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 31.6       |\n",
      "|    success_rate         | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1608       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01355462 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.08      |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.32       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    value_loss           | 22.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 33.1        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012482928 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.69        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 33.6         |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127247535 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.05        |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.98         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0375      |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 35.9       |\n",
      "|    success_rate         | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1570       |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01269187 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4         |\n",
      "|    explained_variance   | 0.742      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    value_loss           | 27.6       |\n",
      "----------------------------------------\n",
      "New best trajectory found with reward: [80.]\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 34.2        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012736593 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.91        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 34.5        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013015983 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "New best trajectory found with reward: [90.]\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 34.1         |\n",
      "|    success_rate         | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124606835 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.038       |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 36.4        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013013743 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0368     |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 42.5        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013493138 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 40.1        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014049073 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 44          |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014078824 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "New best trajectory found with reward: [100.]\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 47.5        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011807581 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 46.6        |\n",
      "|    success_rate         | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014943796 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fcd2a7b6510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=4 cmp_res=0', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=0', 'example_2': 'rdi=1 rsi=3 rax=3 rdx=2 rcx=4 cmp_res=0', 'example_3': 'rdi=1 rsi=3 rax=3 rdx=4 rcx=2 cmp_res=0', 'example_4': 'rdi=1 rsi=4 rax=4 rdx=2 rcx=3 cmp_res=0', 'example_5': 'rdi=1 rsi=4 rax=4 rdx=3 rcx=2 cmp_res=0', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=4 cmp_res=0', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=0', 'example_8': 'rdi=2 rsi=3 rax=3 rdx=1 rcx=4 cmp_res=0', 'example_9': 'rdi=2 rsi=3 rax=3 rdx=4 rcx=1 cmp_res=0', 'example_10': 'rdi=2 rsi=4 rax=4 rdx=1 rcx=3 cmp_res=0', 'example_11': 'rdi=2 rsi=4 rax=4 rdx=3 rcx=1 cmp_res=0', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=4 cmp_res=0', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=0', 'example_14': 'rdi=3 rsi=2 rax=2 rdx=1 rcx=4 cmp_res=0', 'example_15': 'rdi=3 rsi=2 rax=2 rdx=4 rcx=1 cmp_res=0', 'example_16': 'rdi=3 rsi=4 rax=4 rdx=1 rcx=2 cmp_res=0', 'example_17': 'rdi=3 rsi=4 rax=4 rdx=2 rcx=1 cmp_res=0', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=3 cmp_res=0', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=0', 'example_20': 'rdi=4 rsi=2 rax=2 rdx=1 rcx=3 cmp_res=0', 'example_21': 'rdi=4 rsi=2 rax=2 rdx=3 rcx=1 cmp_res=0', 'example_22': 'rdi=4 rsi=3 rax=3 rdx=1 rcx=2 cmp_res=0', 'example_23': 'rdi=4 rsi=3 rax=3 rdx=2 rcx=1 cmp_res=0', 'is_success': False} 30\n",
      "(<Instruction.CMP: 1>, <Operand.RDX: 2>, <Operand.RCX: 3>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=4 cmp_res=True', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=False', 'example_2': 'rdi=1 rsi=3 rax=3 rdx=2 rcx=4 cmp_res=True', 'example_3': 'rdi=1 rsi=3 rax=3 rdx=4 rcx=2 cmp_res=False', 'example_4': 'rdi=1 rsi=4 rax=4 rdx=2 rcx=3 cmp_res=True', 'example_5': 'rdi=1 rsi=4 rax=4 rdx=3 rcx=2 cmp_res=False', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=4 cmp_res=True', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=3 rax=3 rdx=1 rcx=4 cmp_res=True', 'example_9': 'rdi=2 rsi=3 rax=3 rdx=4 rcx=1 cmp_res=False', 'example_10': 'rdi=2 rsi=4 rax=4 rdx=1 rcx=3 cmp_res=True', 'example_11': 'rdi=2 rsi=4 rax=4 rdx=3 rcx=1 cmp_res=False', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=4 cmp_res=True', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=2 rax=2 rdx=1 rcx=4 cmp_res=True', 'example_15': 'rdi=3 rsi=2 rax=2 rdx=4 rcx=1 cmp_res=False', 'example_16': 'rdi=3 rsi=4 rax=4 rdx=1 rcx=2 cmp_res=True', 'example_17': 'rdi=3 rsi=4 rax=4 rdx=2 rcx=1 cmp_res=False', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=3 cmp_res=True', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=2 rax=2 rdx=1 rcx=3 cmp_res=True', 'example_21': 'rdi=4 rsi=2 rax=2 rdx=3 rcx=1 cmp_res=False', 'example_22': 'rdi=4 rsi=3 rax=3 rdx=1 rcx=2 cmp_res=True', 'example_23': 'rdi=4 rsi=3 rax=3 rdx=2 rcx=1 cmp_res=False', 'is_success': False} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RDX: 2>, <Operand.RCX: 3>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=3 cmp_res=True', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=False', 'example_2': 'rdi=1 rsi=3 rax=3 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=3 rax=3 rdx=4 rcx=2 cmp_res=False', 'example_4': 'rdi=1 rsi=4 rax=4 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=4 rax=4 rdx=3 rcx=2 cmp_res=False', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=True', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=3 rax=3 rdx=1 rcx=1 cmp_res=True', 'example_9': 'rdi=2 rsi=3 rax=3 rdx=4 rcx=1 cmp_res=False', 'example_10': 'rdi=2 rsi=4 rax=4 rdx=1 rcx=1 cmp_res=True', 'example_11': 'rdi=2 rsi=4 rax=4 rdx=3 rcx=1 cmp_res=False', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=True', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=2 rax=2 rdx=1 rcx=1 cmp_res=True', 'example_15': 'rdi=3 rsi=2 rax=2 rdx=4 rcx=1 cmp_res=False', 'example_16': 'rdi=3 rsi=4 rax=4 rdx=1 rcx=1 cmp_res=True', 'example_17': 'rdi=3 rsi=4 rax=4 rdx=2 rcx=1 cmp_res=False', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=True', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=2 rax=2 rdx=1 rcx=1 cmp_res=True', 'example_21': 'rdi=4 rsi=2 rax=2 rdx=3 rcx=1 cmp_res=False', 'example_22': 'rdi=4 rsi=3 rax=3 rdx=1 rcx=1 cmp_res=True', 'example_23': 'rdi=4 rsi=3 rax=3 rdx=2 rcx=1 cmp_res=False', 'is_success': False} 0\n",
      "(<Instruction.CMP: 1>, <Operand.RCX: 3>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=3 cmp_res=False', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=False', 'example_2': 'rdi=1 rsi=3 rax=3 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=3 rax=3 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=4 rax=4 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=4 rax=4 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=3 rax=3 rdx=1 rcx=1 cmp_res=True', 'example_9': 'rdi=2 rsi=3 rax=3 rdx=4 rcx=1 cmp_res=True', 'example_10': 'rdi=2 rsi=4 rax=4 rdx=1 rcx=1 cmp_res=True', 'example_11': 'rdi=2 rsi=4 rax=4 rdx=3 rcx=1 cmp_res=True', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=2 rax=2 rdx=1 rcx=1 cmp_res=True', 'example_15': 'rdi=3 rsi=2 rax=2 rdx=4 rcx=1 cmp_res=True', 'example_16': 'rdi=3 rsi=4 rax=4 rdx=1 rcx=1 cmp_res=True', 'example_17': 'rdi=3 rsi=4 rax=4 rdx=2 rcx=1 cmp_res=True', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=2 rax=2 rdx=1 rcx=1 cmp_res=True', 'example_21': 'rdi=4 rsi=2 rax=2 rdx=3 rcx=1 cmp_res=True', 'example_22': 'rdi=4 rsi=3 rax=3 rdx=1 rcx=1 cmp_res=True', 'example_23': 'rdi=4 rsi=3 rax=3 rdx=2 rcx=1 cmp_res=True', 'is_success': False} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=3 cmp_res=False', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=False', 'example_2': 'rdi=1 rsi=3 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=3 rax=2 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=4 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=4 rax=2 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=3 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_9': 'rdi=2 rsi=3 rax=1 rdx=4 rcx=1 cmp_res=True', 'example_10': 'rdi=2 rsi=4 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_11': 'rdi=2 rsi=4 rax=1 rdx=3 rcx=1 cmp_res=True', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_15': 'rdi=3 rsi=2 rax=1 rdx=4 rcx=1 cmp_res=True', 'example_16': 'rdi=3 rsi=4 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_17': 'rdi=3 rsi=4 rax=1 rdx=2 rcx=1 cmp_res=True', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=2 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_21': 'rdi=4 rsi=2 rax=1 rdx=3 rcx=1 cmp_res=True', 'example_22': 'rdi=4 rsi=3 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_23': 'rdi=4 rsi=3 rax=1 rdx=2 rcx=1 cmp_res=True', 'is_success': False} 60\n",
      "(<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RSI: 1>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=3 cmp_res=False', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=False', 'example_2': 'rdi=1 rsi=2 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=2 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_9': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=True', 'example_10': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_11': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=True', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_15': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=True', 'example_16': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_17': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=True', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_21': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=True', 'example_22': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_23': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=True', 'is_success': False} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RCX: 3>, <Operand.RSI: 1>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=3 cmp_res=False', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=False', 'example_2': 'rdi=1 rsi=2 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=2 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_9': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=True', 'example_10': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_11': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=True', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_15': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=True', 'example_16': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_17': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=True', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_21': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=True', 'example_22': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=True', 'example_23': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=True', 'is_success': False} 0\n",
      "(<Instruction.CMP: 1>, <Operand.RDI: 0>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=3 cmp_res=True', 'example_1': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=3 cmp_res=True', 'example_2': 'rdi=1 rsi=2 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=2 rax=2 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=2 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=2 rax=2 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_9': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=False', 'example_10': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_11': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=False', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_15': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=False', 'example_16': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_17': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=False', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_21': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=False', 'example_22': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_23': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=False', 'is_success': False} 0\n",
      "(<Instruction.CMOVG: 2>, <Operand.RDI: 0>, <Operand.RSI: 1>) {'example_0': 'rdi=1 rsi=1 rax=2 rdx=3 rcx=3 cmp_res=True', 'example_1': 'rdi=1 rsi=1 rax=2 rdx=4 rcx=3 cmp_res=True', 'example_2': 'rdi=1 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=1 rax=2 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=1 rax=2 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=1 rax=2 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_9': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=False', 'example_10': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_11': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=False', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_15': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=False', 'example_16': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_17': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=False', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_21': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=False', 'example_22': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_23': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=False', 'is_success': False} 0\n",
      "(<Instruction.MOV: 0>, <Operand.RSI: 1>, <Operand.RAX: 4>) {'example_0': 'rdi=1 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=True', 'example_1': 'rdi=1 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=True', 'example_2': 'rdi=1 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=True', 'example_3': 'rdi=1 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=True', 'example_4': 'rdi=1 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=True', 'example_5': 'rdi=1 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=True', 'example_6': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=3 cmp_res=False', 'example_7': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=3 cmp_res=False', 'example_8': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_9': 'rdi=2 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=False', 'example_10': 'rdi=2 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_11': 'rdi=2 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=False', 'example_12': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_13': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=2 cmp_res=False', 'example_14': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_15': 'rdi=3 rsi=1 rax=1 rdx=4 rcx=1 cmp_res=False', 'example_16': 'rdi=3 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_17': 'rdi=3 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=False', 'example_18': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=2 cmp_res=False', 'example_19': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=2 cmp_res=False', 'example_20': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_21': 'rdi=4 rsi=1 rax=1 rdx=3 rcx=1 cmp_res=False', 'example_22': 'rdi=4 rsi=1 rax=1 rdx=1 rcx=1 cmp_res=False', 'example_23': 'rdi=4 rsi=1 rax=1 rdx=2 rcx=1 cmp_res=False', 'is_success': True} 120\n",
      "True\n",
      "False\n",
      "Episode finished after 10 timestamps\n",
      "total reward 210\n"
     ]
    }
   ],
   "source": [
    "state, _ = env.reset()\n",
    "cumreward = 0\n",
    "for i in range(MAX_STEPS):\n",
    "  action,_ = model.predict(state)\n",
    "  state, reward, terminated, truncated, info = env.step(action)\n",
    "  cumreward +=reward\n",
    "  print(PROCESSOR_ACTIONS[action], info, reward)\n",
    "  if terminated or truncated:\n",
    "    print(terminated)\n",
    "    print(truncated)\n",
    "    print(f\"Episode finished after {i+1} timestamps\")\n",
    "    break\n",
    "print(f\"total reward {cumreward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
